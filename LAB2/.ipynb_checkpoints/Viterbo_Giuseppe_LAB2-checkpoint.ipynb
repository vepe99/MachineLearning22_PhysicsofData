{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning LAB 2: SUPPORT VECTOR MACHINES\n",
    "Course 2022/23: P. Zanuttigh, M. Mel, F. Barbato\n",
    "\n",
    "The notebook contains some simple tasks to be performed with **SUPPORT VECTOR MACHINES (SVM)**. <br>\n",
    "Complete all the **required code sections** and **answer to all the questions**. <br>\n",
    "\n",
    "### IMPORTANT for the evaluation score:\n",
    "1. **Read carefully all cells** and **follow the instructions**\n",
    "2. **Re-run all the code from the beginning** to obtain the results for the final version of your notebook, since this is the way we will do it before evaluating your notebooks.\n",
    "3. Make sure to fill the code in the appropriate places **without modifying the template**, otherwise you risk breaking later cells.\n",
    "4. Please **submit the jupyter notebook file (.ipynb)**, do not submit python scripts (.py) or plain text files. **Make sure that it runs fine with the restat&run all command**.\n",
    "5. **Answer the questions in the appropriate cells**, not in the ones where the question is presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Classification with Support Vector Machines\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVM) for weather classification. We will use a dataset collected using the Luxottica iSee glasses, similarly to the previous laboratory.\n",
    "The dataset corresponds to 8 hours of atmospherical data recordings sampled every 3 seconds.\n",
    "\n",
    "The dataset labels are the following:\n",
    "\n",
    "| ID | Label |\n",
    "| :-: | :-: |\n",
    "| 0 | Sunny |\n",
    "| 1 | Rain |\n",
    "| 2 | Cloudy |\n",
    "| 3 | Mostly Clear|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place your **name** and **ID number** (matricola) in the cell below. <br>\n",
    "Also recall to **save the file as Surname_Name_LAB2.ipynb**, failure to do so will incur in a **lower grade**.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student name**: Mario Rossi<br>\n",
    "**ID Number**: 1234567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load the dataset\n",
    "def load_dataset(path):\n",
    "    with np.load(path) as data:\n",
    "        x, y = data[\"x\"], data[\"y\"]\n",
    "        \n",
    "        # normalize data\n",
    "        x -= x.mean(axis=0)\n",
    "        x /= x.std(axis=0)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Hyper-parameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.0):** **Set** the random **seed** using your **ID**. If you need to change it for testing add a constant explicitly, eg.: 1234567 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix your ID (\"numero di matricola\") and the seed for random generator\n",
    "# as usual you can try different seeds by adding a constant to the number:\n",
    "# ID = 1234567 + X\n",
    "ID = 1234567\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceding to the training steps, we **load the dataset and split it** in training and test set (while the **training** set is **typically larger**, here we set the number of training samples to 1000 and 4000 for the test data).\n",
    "The **split** is **performed after applying a random permutation** to the dataset, such permutation will **depend on the seed** you set above.<br><br>\n",
    "**DO NOT CHANGE THE PRE-WRITTEN CODE UNLESS OTHERWISE SPECIFIED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset(\"data/lux.npz\")\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The task is quite easy, let's add noise to make it more challenging!\n",
    "# You can try without noise (comment the next 2 lines, easy task), with the suggested amount of noise,\n",
    "# or play with the suggested amount of noise \n",
    "\n",
    "noise = np.random.normal(0,0.1,X.shape)\n",
    "X=X+noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.1):** **Divide** the **data into training and test set** (for this part use 1000 samples in the **first** set, 4000 in the **second** one). Make sure that each label is present at least 10 times in training. If it is not, then keep adding permutations to the initial data until this happens. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random permute the data and split into training and test taking the first 1000\n",
    "#data samples as training and 4000 samples as test\n",
    "permutation =  # ADD YOUR CODE HERE\n",
    "\n",
    "X =  # ADD YOUR CODE HERE\n",
    "y =  # ADD YOUR CODE HERE\n",
    "\n",
    "m_training = 1000\n",
    "m_test = 4000\n",
    "\n",
    "X_train = # ADD YOUR CODE HERE\n",
    "X_test = # ADD YOUR CODE HERE\n",
    "y_train = # ADD YOUR CODE HERE \n",
    "y_test = # ADD YOUR CODE HERE\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape,\"X_test shape:\", X_test.shape,\"||\",\"y_train shape:\",  y_train.shape,\"y_test shape:\", y_test.shape)\n",
    "\n",
    "labels, freqs = # ADD YOUR CODE HERE. Hint: use np.unique()\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    cmap = plt.cm.get_cmap('Accent', 4)\n",
    "    im = ax.scatter(X_matrix[:,0], X_matrix[:,1], X_matrix[:,2], c=labels, cmap=cmap)\n",
    "    im.set_clim(-0.5, 3.5)\n",
    "    cbar=fig.colorbar(im, ticks=[0,1,2,3], orientation='vertical', cmap=cmap)\n",
    "    cbar.ax.set_yticklabels(['Sunny', 'Rainy','Cloudy', 'Mostly clear']) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try the plotting function\n",
    "plot_input(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.2):** Use a SVM classfier with cross validation to pick a model. Use a 4-fold cross-validation. Let's start with a Linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [ 0.01, 0.1, 1, 10]}\n",
    "\n",
    "#train linear SVM\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR LINEAR KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print(\"All scores on the grid:\")\n",
    "# ADD YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.3):** Pick a model for the Polynomial kernel with degree=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=2 KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.4):** Now let's try a higher degree for the polynomial kernel (e.g., 3rd degree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for poly with higher degree kernel\n",
    "parameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1, 1]}\n",
    "\n",
    "#run SVM with poly of higher degree kernel\n",
    "degree = 3\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=', degree, ' KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.5):** Pick a model for the Radial Basis Function kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for rbf SVM\n",
    "parameters = {'C': [0.1, 1, 10, 100],'gamma':[0.001, 0.01, 0.1,1]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR rbf KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.Q1) [Answer the following]** <br> \n",
    "What do you observe when using RBF and polynomial kernels on this dataset ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    **ANSWER A.Q1**:<br>\n",
    "answer here\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.6):** Report here the best SVM kernel and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = # USE YOUR OPTIMAL PARAMETERS\n",
    "\n",
    "# ADD YOUR CODE\n",
    "# (error is 1 - svm.score)\n",
    "training_error = # ADD YOUR CODE\n",
    "test_error = # ADD YOUR CODE\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.7):** Analyze how the gamma parameter (inversely proportional to standard deviation of Gaussian Kernel) impact the performances of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with different values of gamma\n",
    "\n",
    "gamma_values = np.logspace(-5,2,8)\n",
    "print(gamma_values)\n",
    "# use rbf kernel and C=1\n",
    "train_acc_list, test_acc_list = [], []\n",
    "\n",
    "\n",
    "# ADD YOUR CODE TO TRAIN THE SVM MULTIPLE TIMES WITH THE DIFFERENT VALUES OF GAMMA\n",
    "# PLACE THE TRAIN AND TEST ACCURACY FOR EACH TEST IN THE TRAIN AND TEST ACCURACY LISTS\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "ax[0].plot(gamma_values, train_acc_list)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('gamma')\n",
    "ax[0].set_ylabel('Train accuracy')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(gamma_values, test_acc_list)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('gamma')\n",
    "ax[1].set_ylabel('Test accuracy')\n",
    "ax[1].grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) More data\n",
    "Now let's do the same but using more data points for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (B.0):** Choose a higher number of data points (e.g. x = 10000) for training data depending on your computing capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = # ADD YOUR CODE: adjust depending on the capabilities of your PC\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = # ADD YOUR CODE\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n",
    "\n",
    "# initialize support variables for boundaries visualization\n",
    "granularity = 25\n",
    "x_max = np.abs(X).max()\n",
    "x_range = np.linspace(-x_max, x_max, granularity)\n",
    "x_grid = np.stack(np.meshgrid(x_range, x_range, x_range)).reshape(3, -1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (B.1):** Let's try to use SVM with parameters obtained from the best model for $m_{training} =  10000$. Since it may take a long time to run, you can decide to just let it run for some time and stop it if it does not complete. If you decide to do this, report it in the TO DO (C.Q1) cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (B.2):** Just for comparison, let's also use logistic regression (without regularization, i.e. with C very large)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# ADD YOUR CODE\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (B.3):** Try logistic regression with regularization (use C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE\n",
    "\n",
    "print (\"Best regularized logistic regression training error: %f\" % training_error)\n",
    "print (\"Best regularized logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Boundaries Visualization\n",
    "\n",
    "Now let us compare the shape of classification boundaries. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (C.0):** Use the SVM, logistic regression (with and without regularization) to predict on the test set X_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_SVM_test = # ADD YOUR CODE\n",
    "lr_test = # ADD YOUR CODE \n",
    "regL2_test = # ADD YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We constructed a grid of all possible combinations of input values, we now use it to extract the classification boundaries of the three classifiers by having them predict on each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rbf_SVM_grid = rbf_SVM.predict(x_grid)\n",
    "lr_grid = lr.predict(x_grid)\n",
    "regL2_grid = regL2.predict(x_grid)\n",
    "\n",
    "\n",
    "rbf_SVM_m = y_test == rbf_SVM_test\n",
    "lr_m = y_test == lr_test\n",
    "regL2_m = y_test == lr_test\n",
    "\n",
    "fig = plt.figure(figsize=(20,36))\n",
    "ax1 = fig.add_subplot(1, 3, 1, projection=\"3d\")\n",
    "ax2 = fig.add_subplot(1, 3, 2, projection=\"3d\")\n",
    "ax3 = fig.add_subplot(1, 3, 3, projection=\"3d\")\n",
    "\n",
    "ax1.scatter(x_grid[:,0], x_grid[:,1], x_grid[:,2], c=rbf_SVM_grid, linewidth=0, marker=\"s\", alpha=.05,cmap='Accent')\n",
    "ax2.scatter(x_grid[:,0], x_grid[:,1], x_grid[:,2], c=lr_grid, linewidth=0, marker=\"s\", alpha=.05,cmap='Accent')\n",
    "ax3.scatter(x_grid[:,0], x_grid[:,1], x_grid[:,2], c=regL2_grid, linewidth=0, marker=\"s\", alpha=.05,cmap='Accent')\n",
    "\n",
    "ax1.scatter(X_test[rbf_SVM_m,0], X_test[rbf_SVM_m,1], X_test[rbf_SVM_m,2], c=y_test[rbf_SVM_m], linewidth=.5, edgecolor=\"k\", marker=\".\",cmap='Accent')\n",
    "ax1.scatter(X_test[~rbf_SVM_m,0], X_test[~rbf_SVM_m,1], X_test[~rbf_SVM_m,2], c=y_test[~rbf_SVM_m], linewidth=1, edgecolor=\"r\", marker=\".\",cmap='Accent')\n",
    "ax1.set_xlim([-x_max, x_max])\n",
    "ax1.set_ylim([-x_max, x_max])\n",
    "ax1.set_zlim([-x_max, x_max])\n",
    "\n",
    "ax2.scatter(X_test[lr_m,0], X_test[lr_m,1], X_test[lr_m,2], c=y_test[lr_m], linewidth=.5, edgecolor=\"k\", marker=\".\",cmap='Accent')\n",
    "ax2.scatter(X_test[~lr_m,0], X_test[~lr_m,1], X_test[~lr_m,2], c=y_test[~lr_m], linewidth=1, edgecolor=\"r\", marker=\".\",cmap='Accent')\n",
    "ax2.set_xlim([-x_max, x_max])\n",
    "ax2.set_ylim([-x_max, x_max])\n",
    "ax2.set_zlim([-x_max, x_max])\n",
    "\n",
    "ax3.scatter(X_test[regL2_m,0], X_test[regL2_m,1], X_test[regL2_m,2], c=y_test[regL2_m], linewidth=.5, edgecolor=\"k\", marker=\".\",cmap='Accent')\n",
    "ax3.scatter(X_test[~regL2_m,0], X_test[~regL2_m,1], X_test[~regL2_m,2], c=y_test[~regL2_m], linewidth=1, edgecolor=\"r\", marker=\".\",cmap='Accent')\n",
    "ax3.set_xlim([-x_max, x_max])\n",
    "ax3.set_ylim([-x_max, x_max])\n",
    "ax3.set_zlim([-x_max, x_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (C.Q1) [Answer the following]** <br> \n",
    "Compare and discuss:\n",
    "- the results from SVM with m=600 and with m=10000 (or whatever value you set) training data points. If you stopped the SVM, include such aspect in your comparison.\n",
    "- the results of SVM and of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "**ANSWER C.Q1**:<br>\n",
    "answer here\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (C.1):** Change the code below to highlight the samples classified correctly by SVM and wrongly by logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "mask =  # ADD YOUR CODE\n",
    "\n",
    "ax.scatter(X_test[mask,0], X_test[mask,1], X_test[mask,2], c=y_test[mask], linewidth=1, edgecolor=\"c\", marker=\".\")\n",
    "ax.scatter(X_test[~mask,0], X_test[~mask,1], X_test[~mask,2], c=y_test[~mask], linewidth=.5, edgecolor=\"k\", marker=\".\")\n",
    "ax.set_xlim([-x_max, x_max])\n",
    "ax.set_ylim([-x_max, x_max])\n",
    "ax.set_zlim([-x_max, x_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (C.2):** Plot the confusion matrix for the SVM classifier and for logistic regression. The confusion matrix has one column for each predicted label and one row for each true label. \n",
    "It shows for each class in the corresponding row how many samples belonging to that class gets each possible output label. Notice that the diagonal contains the correctly classified samples, while the other cells correspond to errors. You can obtain it with the sklearn.metrics.confusion_matrix function (see the documentation). You can also print also the normalized confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True) # for better aligned printing of confusion matrix use floatmode='fixed'\n",
    "\n",
    "u, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Labels and frequencies in test set: \", counts)\n",
    "\n",
    "confusion_SVM =  # ADD YOUR CODE\n",
    "print(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM)\n",
    "print(\"\\n Confusion matrix SVM (normalized)   \\n \\n\", confusion_SVM /counts[:,None] )\n",
    "\n",
    "confusion_LR =  # ADD YOUR CODE\n",
    "print(\"\\n Confusion matrix LR  \\n \\n\", confusion_LR)\n",
    "print(\"\\n Confusion matrix LR (normalized)   \\n \\n\", confusion_LR /counts[:,None] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "for idx, conf in enumerate([confusion_SVM, confusion_LR]):\n",
    "    \n",
    "    im = axs[idx].imshow(conf /counts[:,None], cmap=\"Blues\",interpolation='nearest')\n",
    "    axs[idx].set_xticks([0,1,2,3])\n",
    "    axs[idx].set_yticks([0,1,2,3])\n",
    "    axs[idx].set_xticklabels(['Sunny', 'Rainy','Cloudy', 'Mostly clear'],ha=\"right\",rotation=30) \n",
    "    axs[idx].set_yticklabels(['Sunny', 'Rainy','Cloudy', 'Mostly clear'],ha=\"right\",rotation=30) \n",
    "    cm = conf /counts[:,None]\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            axs[idx].text(j, i, format(cm[i, j], fmt),\n",
    "            ha=\"center\", va=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.colorbar(im, ax=axs[:], location='bottom')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (C.Q2) [Answer the following]** <br> \n",
    "Have a look at the confusion matrices and comment on the obtained accuracies. Why some classes have lower accuracies and others an higher one ? Make some guesses on the possible causes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    **ANSWER C.Q2**:<br>\n",
    "answer here\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
